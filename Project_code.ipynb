{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":351698,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":293517,"modelId":314148},{"sourceId":368077,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":304949,"modelId":325394}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/aliniazi3/spotcancerai?scriptVersionId=241933698\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# **Importing Libraries**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#import plotly.express as px\nimport os\nimport itertools\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom sklearn.impute import SimpleImputer\n\nfrom glob import glob\nfrom PIL import Image\nfrom tensorflow.keras.models import Model\nfrom sklearn.model_selection import train_test_split\n#from sklearn.metrics import confusion_matrix, plot_confusion_matrix\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import EfficientNetB5\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras import backend as K\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **DATA READING**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **DATA Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Creating dictionary for displaying more human-friendly labels.**","metadata":{}},{"cell_type":"code","source":"lesion_type_dict = {\n    'nv': 'Melanocytic nevi',\n    'mel': 'Melanoma',\n    'bkl': 'Benign keratosis-like lesions ',\n    'bcc': 'Basal cell carcinoma',\n    'akiec': 'Actinic keratoses',\n    'vasc': 'Vascular lesions',\n    'df': 'Dermatofibroma'\n}\nbase_skin_dir = '../input/skin-cancer-mnist-ham10000'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Merge images from both folders into one dictionary**","metadata":{}},{"cell_type":"code","source":"imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x\n                     for x in glob(os.path.join(base_skin_dir, '*', '*.jpg'))}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Creating new columns for better understanding of features**","metadata":{}},{"cell_type":"code","source":"df['path'] = df['image_id'].map(imageid_path_dict.get)\ndf['cell_type'] = df['dx'].map(lesion_type_dict.get)\ndf['cell_type_idx'] = pd.Categorical(df['cell_type']).codes\n\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def preprocess_image(image_path, IMAGE_SIZE=456):  \n    img = cv2.imread(image_path)\n    img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, cv2.getStructuringElement(cv2.MORPH_RECT, (17, 17)))\n    inpainted = cv2.inpaint(img, blackhat, 1, cv2.INPAINT_TELEA)\n    denoised = cv2.GaussianBlur(inpainted, (7, 7), 0)\n    return denoised\n\n\n# Drop missing paths\ndf = df.dropna(subset=['path'])\n\n# Select one sample image per class\nsample_images = df.groupby('cell_type').first().reset_index()\n\nplt.figure(figsize=(14, 5))\nfor i, row in enumerate(sample_images.itertuples(), 1):\n    if i > 7: break  # Limit to 7 images\n    \n    original_image = cv2.imread(row.path)\n    processed_image = preprocess_image(row.path)\n    \n    original_image_rgb = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n    \n    plt.subplot(2, 7, i)\n    plt.imshow(original_image_rgb)\n    plt.title(f\"Original\\n{row.cell_type}\")\n    plt.axis(\"off\")\n    \n    plt.subplot(2, 7, i + 7)\n    plt.imshow(processed_image, cmap=\"gray\")\n    plt.title(\"Processed\")\n    plt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\n\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tabular_data = pd.read_csv('/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv')\ntabular_data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Exploratory Data Analysis (EDA)**","metadata":{}},{"cell_type":"code","source":"tabular_data.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classes = {\n    0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),\n    1: ('bcc', ' basal cell carcinoma'),\n    2: ('bkl', 'benign keratosis-like lesions'),\n    3: ('df', 'dermatofibroma'),\n    4: ('nv', ' melanocytic nevi'),\n    5: ('vasc', ' pyogenic granulomas and hemorrhage'),\n    6: ('mel', 'melanoma')\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Frequency Distribution of Classes**","metadata":{}},{"cell_type":"code","source":"sns.countplot(x = 'dx', data = tabular_data)\nplt.xlabel('Disease', size=12)\nplt.ylabel('Frequency', size=12)\nplt.title('Frequency Distribution of Classes', size=16)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Distribution of Disease over Gender**","metadata":{}},{"cell_type":"code","source":"bar, ax = plt.subplots(figsize = (10,10))\nplt.pie(tabular_data['sex'].value_counts(), labels = tabular_data['sex'].value_counts().index, autopct=\"%.1f%%\")\nplt.title('Gender of Patient', size=16)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Histogram of Age of Patients**","metadata":{}},{"cell_type":"code","source":"bar, ax = plt.subplots(figsize=(10,10))\nsns.histplot(tabular_data['age'])\nplt.title('Histogram of Age of Patients', size=16)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Location of disease over Gender**","metadata":{}},{"cell_type":"code","source":"value = tabular_data[['localization', 'sex']].value_counts().to_frame()\nvalue.reset_index(level=[1,0 ], inplace=True)\ntemp = value.rename(columns = {'localization':'location', 0: 'count'})\n\nbar, ax = plt.subplots(figsize = (12, 12))\nsns.barplot(x = 'location',  y='count', hue = 'sex', data = temp)\nplt.title('Location of disease over Gender', size = 16)\nplt.xlabel('Disease', size=12)\nplt.ylabel('Frequency/Count', size=12)\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split the dataset into features (X) and labels (y)\nX = df['path'].values  # Image file paths\ny = df['cell_type_idx'].values  # Integer labels for the skin cancer types\n\n# Split the dataset into train and test sets (80% training, 20% testing)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n\n# Print the size of the splits\nprint(f\"Training set size: {len(X_train)}\")\nprint(f\"Test set size: {len(X_test)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Combine into DataFrames**","metadata":{}},{"cell_type":"code","source":"# Create train and test DataFrames\ntrain_df = pd.DataFrame({'path': X_train, 'label': y_train})\ntest_df = pd.DataFrame({'path': X_test, 'label': y_test})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Class Balance Using Resampling**","metadata":{}},{"cell_type":"code","source":"class_counts = train_df['label'].value_counts()\nmax_count = class_counts.max()\nprint(\"Original class distribution:\\n\", class_counts)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_dir = \"/kaggle/working/augmented_images\"\nos.makedirs(augmented_dir, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img\nimport uuid\nIMAGE_SIZE= 456\naugmenter = ImageDataGenerator(\n    rotation_range=40,\n    zoom_range=0.3,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\naugmented_records = []\n\nfor label in class_counts.index:\n    current_df = train_df[train_df['label'] == label]\n    n_needed = max_count - len(current_df)\n    \n    if n_needed == 0:\n        continue  # skip majority class\n    \n    print(f\"Augmenting class '{label}' with {n_needed} new images...\")\n    \n    i = 0\n    for idx, row in current_df.iterrows():\n        img = load_img(row['path'], target_size=(IMAGE_SIZE, IMAGE_SIZE))\n        x = img_to_array(img)\n        x = x.reshape((1,) + x.shape)\n        \n        # Generate augmented images\n        for batch in augmenter.flow(x, batch_size=1):\n            save_path = os.path.join(augmented_dir, f\"{uuid.uuid4().hex}.jpg\")\n            array_to_img(batch[0]).save(save_path)\n            augmented_records.append({'path': save_path, 'label': label})\n            i += 1\n            if i >= n_needed:\n                break\n        if i >= n_needed:\n            break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"augmented_df = pd.DataFrame(augmented_records)\nbalanced_train_df = pd.concat([train_df, augmented_df], ignore_index=True)\nbalanced_train_df = balanced_train_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(16, 6))\n\n# --- Plot 1: Original Data Distribution ---\nplt.subplot(1, 2, 1)\nsns.countplot(data=train_df, x='label', order=train_df['label'].value_counts().index)\nplt.title(\"Original Class Distribution\")\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Image Count\")\nplt.xticks(rotation=45)\n\n# --- Plot 2: Balanced Data Distribution ---\nplt.subplot(1, 2, 2)\nsns.countplot(data=balanced_train_df, x='label', order=balanced_train_df['label'].value_counts().index)\nplt.title(\"Balanced Class Distribution (Augmented, No Duplication)\")\nplt.xlabel(\"Class Label\")\nplt.ylabel(\"Image Count\")\nplt.xticks(rotation=45)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **One-hot encode the labels And Data Generators (for categorical classification)**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\n# Ensure labels are string type (important for categorical labels)\nbalanced_train_df['label'] = balanced_train_df['label'].astype(str)\ntest_df['label'] = test_df['label'].astype(str)\n\nIMAGE_SIZE = 456  # EfficientNetB5 input size\nBATCH_SIZE = 32\nSEED = 42  # for reproducibility\n\n# Data generators with augmentation for training, basic preprocessing for testing\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    rotation_range=40,\n    zoom_range=0.3,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    brightness_range=[0.7, 1.3],\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\ntest_datagen = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n)\n\n# Use balanced_train_df here instead of train_df\ntrain_generator = train_datagen.flow_from_dataframe(\n    balanced_train_df,\n    x_col='path',\n    y_col='label',\n    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=True,\n    seed=SEED\n)\n\n\ntest_generator = test_datagen.flow_from_dataframe(\n    test_df,\n    x_col='path',\n    y_col='label',\n    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    shuffle=False,\n    seed=SEED\n)\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Build and compile the EfficientNetB5 model**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import EfficientNetB5\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n# Define image size for EfficientNetB5\nIMAGE_SIZE = 456  # EfficientNetB5 default input size\nBATCH_SIZE = 32\n# Load EfficientNetB5 without top layer\nbase_model = EfficientNetB5(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\nbase_model.trainable = True\nfor layer in base_model.layers[:-20]:  # Freeze all except last 20 layers\n    layer.trainable = False\n    \n# Custom classification head\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.3)(x)\noutput = Dense(len(train_generator.class_indices), activation='softmax')(x)\n\n# Build model\nmodel = Model(inputs=base_model.input, outputs=output)\n\n# Compile model\nmodel.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Print model summary\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Train the model**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.2, min_lr=1e-6)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    validation_data=test_generator,\n    epochs=15,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Example: Find epoch with the highest validation accuracy\nbest_epoch = np.argmax(history.history['accuracy']) + 1  # +1 because indexing starts from 0\nbest_acc = history.history['accuracy'][best_epoch - 1]\n\nprint(f\"Best Epoch: {best_epoch}\")\nprint(f\"Accuracy at Best Epoch: {best_acc:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save('/kaggle/working/final_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Plot Training History (Accuracy & Loss)**","metadata":{}},{"cell_type":"code","source":"# Training curve\nplt.figure(figsize=(14, 6))\n\n# Loss curve\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Loss (training)')\nplt.plot(history.history['val_loss'], label='Loss (validation)')\nplt.title('Loss over the ages')\nplt.xlabel('Eras')\nplt.ylabel('Precision')\nplt.legend()\n\n# Precision curve\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy (training)')\nplt.plot(history.history['val_accuracy'], label='Accuracy (validation)')\nplt.title('Precision over the ages')\nplt.xlabel('Eras')\nplt.ylabel('Precision')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# **Evaluate the Model on Test Data**","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator)\nprint(f\"Test Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Confusion Metrix**","metadata":{}},{"cell_type":"code","source":"# Step 1: Get predictions from the model\ny_prob = model.predict(test_generator)  # Probabilities\ny_pred = np.argmax(y_prob, axis=1)      # Predicted labels\n\n# Step 2: Get true labels from the test generator\ny_true = test_generator.classes          # Actual labels\n\n# Step 3: Get class names from the generator\nCLASS_NAMES = list(test_generator.class_indices.keys())\n\n# Step 4: Generate and plot confusion matrix\ncm = confusion_matrix(y_true, y_pred)\n\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()\n\n# Step 5: Classification report\nprint(\"Classification Report:\\n\")\nprint(classification_report(y_true, y_pred, target_names=CLASS_NAMES))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}